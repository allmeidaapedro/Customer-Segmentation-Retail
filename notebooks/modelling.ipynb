{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine learning customer segmentation project\n",
    "In this project, I will build a machine learning model for customer segmentation. It involves unsupervised learning, using an unlabeled training set for clustering. I intend to perform clustering to summarize customer segments of a retail store, identifying an ideal client group and building a loyalty program.\n",
    "\n",
    "I will use the following pipeline, based on CRISP-DM framework:\n",
    "\n",
    "1. Define the business problem.\n",
    "2. Initial data understanding.\n",
    "3. Exploratory data analysis and feature engineering.\n",
    "4. Data cleaning and preprocessing.\n",
    "5. Group customers into clusters, modelling.\n",
    "6. Interpret the results, analysing the groups created (profiling). \n",
    "7. Provide marketing suggestions and the loyalty program.\n",
    "8. Estimate financial results.\n",
    "\n",
    "In this notebook, I will be covering steps 4 to 8 of the pipeline above. The main objective here is to segment our customers, studying the embedding space, applying techniques such as dimensionality reduction and comparing and evaluating different clustering algorithms in order to make the best segmentation. Moreover, profiles will be created and a loyalty program will be designed, such that concrete financial results will be calculated at the end."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation and visualization.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Modelling.\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OrdinalEncoder, StandardScaler\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Utils.\n",
    "from scripts.modelling_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/marketing_campaign.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Year_Birth</th>\n",
       "      <th>Education</th>\n",
       "      <th>Marital_Status</th>\n",
       "      <th>Income</th>\n",
       "      <th>Kidhome</th>\n",
       "      <th>Teenhome</th>\n",
       "      <th>Dt_Customer</th>\n",
       "      <th>Recency</th>\n",
       "      <th>MntWines</th>\n",
       "      <th>...</th>\n",
       "      <th>NumWebVisitsMonth</th>\n",
       "      <th>AcceptedCmp3</th>\n",
       "      <th>AcceptedCmp4</th>\n",
       "      <th>AcceptedCmp5</th>\n",
       "      <th>AcceptedCmp1</th>\n",
       "      <th>AcceptedCmp2</th>\n",
       "      <th>Complain</th>\n",
       "      <th>Z_CostContact</th>\n",
       "      <th>Z_Revenue</th>\n",
       "      <th>Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5524</td>\n",
       "      <td>1957</td>\n",
       "      <td>Graduation</td>\n",
       "      <td>Single</td>\n",
       "      <td>58138.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>04-09-2012</td>\n",
       "      <td>58</td>\n",
       "      <td>635</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2174</td>\n",
       "      <td>1954</td>\n",
       "      <td>Graduation</td>\n",
       "      <td>Single</td>\n",
       "      <td>46344.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>08-03-2014</td>\n",
       "      <td>38</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4141</td>\n",
       "      <td>1965</td>\n",
       "      <td>Graduation</td>\n",
       "      <td>Together</td>\n",
       "      <td>71613.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21-08-2013</td>\n",
       "      <td>26</td>\n",
       "      <td>426</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6182</td>\n",
       "      <td>1984</td>\n",
       "      <td>Graduation</td>\n",
       "      <td>Together</td>\n",
       "      <td>26646.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10-02-2014</td>\n",
       "      <td>26</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5324</td>\n",
       "      <td>1981</td>\n",
       "      <td>PhD</td>\n",
       "      <td>Married</td>\n",
       "      <td>58293.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>19-01-2014</td>\n",
       "      <td>94</td>\n",
       "      <td>173</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ID  Year_Birth   Education Marital_Status   Income  Kidhome  Teenhome   \n",
       "0  5524        1957  Graduation         Single  58138.0        0         0  \\\n",
       "1  2174        1954  Graduation         Single  46344.0        1         1   \n",
       "2  4141        1965  Graduation       Together  71613.0        0         0   \n",
       "3  6182        1984  Graduation       Together  26646.0        1         0   \n",
       "4  5324        1981         PhD        Married  58293.0        1         0   \n",
       "\n",
       "  Dt_Customer  Recency  MntWines  ...  NumWebVisitsMonth  AcceptedCmp3   \n",
       "0  04-09-2012       58       635  ...                  7             0  \\\n",
       "1  08-03-2014       38        11  ...                  5             0   \n",
       "2  21-08-2013       26       426  ...                  4             0   \n",
       "3  10-02-2014       26        11  ...                  6             0   \n",
       "4  19-01-2014       94       173  ...                  5             0   \n",
       "\n",
       "   AcceptedCmp4  AcceptedCmp5  AcceptedCmp1  AcceptedCmp2  Complain   \n",
       "0             0             0             0             0         0  \\\n",
       "1             0             0             0             0         0   \n",
       "2             0             0             0             0         0   \n",
       "3             0             0             0             0         0   \n",
       "4             0             0             0             0         0   \n",
       "\n",
       "   Z_CostContact  Z_Revenue  Response  \n",
       "0              3         11         1  \n",
       "1              3         11         0  \n",
       "2              3         11         0  \n",
       "3              3         11         0  \n",
       "4              3         11         0  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset has 2240 rows and 29 columns.\n"
     ]
    }
   ],
   "source": [
    "print(f'The dataset has {df.shape[0]} rows and {df.shape[1]} columns.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering\n",
    "Obtaining the final dataset for clustering, applying all the feature engineering and data cleaning at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_df = feature_engineering(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['education', 'marital_status', 'income', 'recency', 'mntwines',\n",
       "       'mntfruits', 'mntmeatproducts', 'mntfishproducts', 'mntsweetproducts',\n",
       "       'mntgoldprods', 'numdealspurchases', 'numwebpurchases',\n",
       "       'numcatalogpurchases', 'numstorepurchases', 'numwebvisitsmonth',\n",
       "       'total_accepted_cmp', 'children', 'age', 'relationship_duration',\n",
       "       'frequency', 'monetary', 'avg_purchase_value'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clustering_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The clustering dataset has 2228 rows and 22 columns.\n"
     ]
    }
   ],
   "source": [
    "print(f'The clustering dataset has {clustering_df.shape[0]} rows and {clustering_df.shape[1]} columns.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Data cleaning and preprocessing\n",
    "- In order to fit machine learning algorithms, there are some transformations we need to apply to the data\n",
    "- Outliers: I have already treated the outliers, removing those representing inconsistent information.\n",
    "- Missing values: I will replace the missing values in income column using KNNImputer, in order to avoid biased clustering results. It will take the mean income from the nearest n_neighbors for imputing.\n",
    "- Numerical features: Some clustering algorithms are sensitive to feature scaling because they use distance calculations such as euclidean distance for training and predicting. Thus, I will apply StandardScaler to numeric attributes.\n",
    "- Categorical features: I intend to apply OrdinalEncoder to the categorical features because education has an ordinal relationship and marital status has only two categories, which will be encoded as 0 and 1. Moreover, I will scale these features after encoding because some clustering algorithms are sensitive to it, due to distance calculations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "education                 0\n",
       "marital_status            0\n",
       "income                   23\n",
       "recency                   0\n",
       "mntwines                  0\n",
       "mntfruits                 0\n",
       "mntmeatproducts           0\n",
       "mntfishproducts           0\n",
       "mntsweetproducts          0\n",
       "mntgoldprods              0\n",
       "numdealspurchases         0\n",
       "numwebpurchases           0\n",
       "numcatalogpurchases       0\n",
       "numstorepurchases         0\n",
       "numwebvisitsmonth         0\n",
       "total_accepted_cmp        0\n",
       "children                  0\n",
       "age                       0\n",
       "relationship_duration     0\n",
       "frequency                 0\n",
       "monetary                  0\n",
       "avg_purchase_value        2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clustering_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will build the preprocessor below, following the techniques mentioned above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 20 numerical features. They are: \n",
      "['income', 'recency', 'mntwines', 'mntfruits', 'mntmeatproducts', 'mntfishproducts', 'mntsweetproducts', 'mntgoldprods', 'numdealspurchases', 'numwebpurchases', 'numcatalogpurchases', 'numstorepurchases', 'numwebvisitsmonth', 'total_accepted_cmp', 'children', 'age', 'relationship_duration', 'frequency', 'monetary', 'avg_purchase_value']\n",
      "There are 2 categorical features. They are: \n",
      "['education', 'marital_status']\n"
     ]
    }
   ],
   "source": [
    "numerical_features = clustering_df.select_dtypes('number').columns.to_list()\n",
    "categorical_features = clustering_df.select_dtypes('object').columns.to_list()\n",
    "\n",
    "print(f'There are {len(numerical_features)} numerical features. They are: ')\n",
    "print(numerical_features)\n",
    "print(f'There are {len(categorical_features)} categorical features. They are: ')\n",
    "print(categorical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pipeline = Pipeline(steps=[\n",
    "    ('knn_imputer', KNNImputer()),\n",
    "    ('std_scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "cat_pipeline = Pipeline(steps=[\n",
    "    ('ordinal_encoder', OrdinalEncoder()),\n",
    "    ('std_scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', num_pipeline, numerical_features),\n",
    "        ('cat', cat_pipeline, categorical_features)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting the preprocessor and converting to DataFrame in order to perform embedding space study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepared_df = pd.DataFrame(preprocessor.fit_transform(clustering_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepared_df.columns = clustering_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>education</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>income</th>\n",
       "      <th>recency</th>\n",
       "      <th>mntwines</th>\n",
       "      <th>mntfruits</th>\n",
       "      <th>mntmeatproducts</th>\n",
       "      <th>mntfishproducts</th>\n",
       "      <th>mntsweetproducts</th>\n",
       "      <th>mntgoldprods</th>\n",
       "      <th>...</th>\n",
       "      <th>numcatalogpurchases</th>\n",
       "      <th>numstorepurchases</th>\n",
       "      <th>numwebvisitsmonth</th>\n",
       "      <th>total_accepted_cmp</th>\n",
       "      <th>children</th>\n",
       "      <th>age</th>\n",
       "      <th>relationship_duration</th>\n",
       "      <th>frequency</th>\n",
       "      <th>monetary</th>\n",
       "      <th>avg_purchase_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.317619</td>\n",
       "      <td>0.307307</td>\n",
       "      <td>0.979727</td>\n",
       "      <td>1.550286</td>\n",
       "      <td>1.755827</td>\n",
       "      <td>2.456149</td>\n",
       "      <td>1.471551</td>\n",
       "      <td>0.842345</td>\n",
       "      <td>0.358429</td>\n",
       "      <td>1.405182</td>\n",
       "      <td>...</td>\n",
       "      <td>0.689529</td>\n",
       "      <td>-0.439298</td>\n",
       "      <td>-1.267017</td>\n",
       "      <td>1.015275</td>\n",
       "      <td>1.501310</td>\n",
       "      <td>1.039875</td>\n",
       "      <td>1.684878</td>\n",
       "      <td>1.129377</td>\n",
       "      <td>-0.892864</td>\n",
       "      <td>1.345208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.253280</td>\n",
       "      <td>-0.383626</td>\n",
       "      <td>-0.873488</td>\n",
       "      <td>-0.637803</td>\n",
       "      <td>-0.730377</td>\n",
       "      <td>-0.651835</td>\n",
       "      <td>-0.633150</td>\n",
       "      <td>-0.731880</td>\n",
       "      <td>-0.169383</td>\n",
       "      <td>-1.118159</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.139543</td>\n",
       "      <td>-0.439298</td>\n",
       "      <td>1.393599</td>\n",
       "      <td>1.271558</td>\n",
       "      <td>-1.420017</td>\n",
       "      <td>-1.091331</td>\n",
       "      <td>-0.962467</td>\n",
       "      <td>-0.983387</td>\n",
       "      <td>-0.892864</td>\n",
       "      <td>1.345208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.969888</td>\n",
       "      <td>-0.798186</td>\n",
       "      <td>0.359019</td>\n",
       "      <td>0.569418</td>\n",
       "      <td>-0.173283</td>\n",
       "      <td>1.340931</td>\n",
       "      <td>-0.149310</td>\n",
       "      <td>-0.040757</td>\n",
       "      <td>-0.697195</td>\n",
       "      <td>1.405182</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.554079</td>\n",
       "      <td>-0.439298</td>\n",
       "      <td>-1.267017</td>\n",
       "      <td>0.331856</td>\n",
       "      <td>0.040647</td>\n",
       "      <td>0.810670</td>\n",
       "      <td>0.284616</td>\n",
       "      <td>0.155932</td>\n",
       "      <td>-0.892864</td>\n",
       "      <td>-0.743380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.206779</td>\n",
       "      <td>-0.798186</td>\n",
       "      <td>-0.873488</td>\n",
       "      <td>-0.562352</td>\n",
       "      <td>-0.665920</td>\n",
       "      <td>-0.505577</td>\n",
       "      <td>-0.584766</td>\n",
       "      <td>-0.751077</td>\n",
       "      <td>-0.169383</td>\n",
       "      <td>-0.757682</td>\n",
       "      <td>...</td>\n",
       "      <td>0.274993</td>\n",
       "      <td>-0.439298</td>\n",
       "      <td>0.063291</td>\n",
       "      <td>-1.291266</td>\n",
       "      <td>-1.420017</td>\n",
       "      <td>-0.796447</td>\n",
       "      <td>-0.919177</td>\n",
       "      <td>-0.908784</td>\n",
       "      <td>-0.892864</td>\n",
       "      <td>-0.743380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.325122</td>\n",
       "      <td>1.550987</td>\n",
       "      <td>-0.392365</td>\n",
       "      <td>0.418516</td>\n",
       "      <td>-0.214720</td>\n",
       "      <td>0.152585</td>\n",
       "      <td>-0.004159</td>\n",
       "      <td>-0.559099</td>\n",
       "      <td>1.414053</td>\n",
       "      <td>0.323750</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.139543</td>\n",
       "      <td>-0.439298</td>\n",
       "      <td>0.063291</td>\n",
       "      <td>-1.034984</td>\n",
       "      <td>-1.420017</td>\n",
       "      <td>0.825414</td>\n",
       "      <td>-0.304793</td>\n",
       "      <td>-0.361616</td>\n",
       "      <td>0.572012</td>\n",
       "      <td>-0.743380</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   education  marital_status    income   recency  mntwines  mntfruits   \n",
       "0   0.317619        0.307307  0.979727  1.550286  1.755827   2.456149  \\\n",
       "1  -0.253280       -0.383626 -0.873488 -0.637803 -0.730377  -0.651835   \n",
       "2   0.969888       -0.798186  0.359019  0.569418 -0.173283   1.340931   \n",
       "3  -1.206779       -0.798186 -0.873488 -0.562352 -0.665920  -0.505577   \n",
       "4   0.325122        1.550987 -0.392365  0.418516 -0.214720   0.152585   \n",
       "\n",
       "   mntmeatproducts  mntfishproducts  mntsweetproducts  mntgoldprods  ...   \n",
       "0         1.471551         0.842345          0.358429      1.405182  ...  \\\n",
       "1        -0.633150        -0.731880         -0.169383     -1.118159  ...   \n",
       "2        -0.149310        -0.040757         -0.697195      1.405182  ...   \n",
       "3        -0.584766        -0.751077         -0.169383     -0.757682  ...   \n",
       "4        -0.004159        -0.559099          1.414053      0.323750  ...   \n",
       "\n",
       "   numcatalogpurchases  numstorepurchases  numwebvisitsmonth   \n",
       "0             0.689529          -0.439298          -1.267017  \\\n",
       "1            -0.139543          -0.439298           1.393599   \n",
       "2            -0.554079          -0.439298          -1.267017   \n",
       "3             0.274993          -0.439298           0.063291   \n",
       "4            -0.139543          -0.439298           0.063291   \n",
       "\n",
       "   total_accepted_cmp  children       age  relationship_duration  frequency   \n",
       "0            1.015275  1.501310  1.039875               1.684878   1.129377  \\\n",
       "1            1.271558 -1.420017 -1.091331              -0.962467  -0.983387   \n",
       "2            0.331856  0.040647  0.810670               0.284616   0.155932   \n",
       "3           -1.291266 -1.420017 -0.796447              -0.919177  -0.908784   \n",
       "4           -1.034984 -1.420017  0.825414              -0.304793  -0.361616   \n",
       "\n",
       "   monetary  avg_purchase_value  \n",
       "0 -0.892864            1.345208  \n",
       "1 -0.892864            1.345208  \n",
       "2 -0.892864           -0.743380  \n",
       "3 -0.892864           -0.743380  \n",
       "4  0.572012           -0.743380  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepared_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimensionality reduction (PCA)\n",
    "I apply PCA, a dimensionality reduction technique for some reasons:\n",
    "\n",
    "- By embedding the original customer data into a lower dimensional space, clustering algorithms can be applied more effectively.\n",
    "- Dimensionality reduction will help us removing noise in the data. Clustering algorithms can be pretty sensitive to outliers and noise.\n",
    "- By embedding the original customer data into a lower dimensional space, it will be possible to effectively visualize the clusters created. This is pretty useful, since it is tough to evaluate clustering algorithms, even using metrics such as silhouette score."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
